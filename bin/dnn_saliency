#! /usr/bin/env python

"""
Find the saliency parts of an image that contributes to
the activation of the specified channel.
"""

import argparse
import numpy as np

from os.path import join as pjoin
from PIL import Image
from dnnbrain.dnn.base import ip
from dnnbrain.dnn.core import Stimulus
from dnnbrain.utils.plot import imgarray_show
from dnnbrain.dnn import models as db_models  # used by eval
from dnnbrain.dnn.algo import GuidedSaliencyImage, VanillaSaliencyImage


def main():
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('-net',
                        metavar='Net',
                        required=True,
                        type=str,
                        help='a neural network name')
    parser.add_argument('-layer',
                        metavar='Layer',
                        required=True,
                        type=str,
                        help="specify the layer"
                             "E.g., 'conv1' represents the first convolution layer and 'fc1' represents the first full connection layer.")
    parser.add_argument('-chn',
                        metavar='Channel',
                        required=True,
                        type=int,
                        nargs='+',
                        help="Channel numbers used to specify which channels are used to find salience images")
    parser.add_argument('-stim',
                        metavar='Stimulus',
                        required=True,
                        type=str,
                        help='a .stim.csv file which contains stimulus information')
    parser.add_argument('-meth',
                        metavar='Method',
                        default='guided',
                        choices=('guided', 'vanilla'),
                        help='the method used to generate the saliency image')
    parser.add_argument('-mode',
                        metavar='Mode',
                        default='RGB',
                        choices=('RGB', 'gray'),
                        help='Visualization mode of the saliency image.'
                             'RGB: visualize derivatives directly; '
                             'gray: retain the maximal magnitude of RGB channels for each pixel, '
                             '    and visualize as a gray image. Note: -cmap, -vmin and -vmax '
                             '    options are only valid at the gray mode.')
    parser.add_argument('-cmap',
                        metavar='Colormap',
                        type=str,
                        default='coolwarm',
                        help='show salience images with the specified colormap')
    parser.add_argument('-vmin',
                        metavar='Vmin',
                        type=float,
                        help='The minimal value used in colormap is applied in all salience images.'
                             'Default is the minimal value of each salience image for itself.')
    parser.add_argument('-vmax',
                        metavar='Vmax',
                        type=float,
                        help='The maximal value used in colormap is applied in all salience images.'
                             'Default is the maximal value of each salience image for itself.')
    parser.add_argument('-show',
                        action='store_true',
                        help='If used, display stimuli and salience images in figures.')
    parser.add_argument('-out',
                        metavar='Output',
                        type=str,
                        help='an output directory where the figures are saved')
    args = parser.parse_args()
    assert len(args.chn) <= 5, "Don't support view more than 5 channels at once!"

    # load objects
    dnn = eval('db_models.{}()'.format(args.net))  # load DNN
    # load stimuli
    stimuli = Stimulus()
    stimuli.load(args.stim)
    # prepare saliency
    if args.meth == 'guided':
        saliency = GuidedSaliencyImage(dnn)
    else:
        saliency = VanillaSaliencyImage(dnn)

    # compute DNN activation batch-wise
    count = 1
    n_row = len(args.chn) + 1
    batch_size = 6
    n_stim = len(stimuli)
    batch_indices = list(range(0, n_stim, batch_size)) + [n_stim]
    for idx, bat_idx in enumerate(batch_indices[:-1]):
        stim = stimuli[bat_idx:batch_indices[idx+1]]

        # -prepare images-
        # prepare original images
        pil_imgs = []
        out_imgs = []
        for stim_id in stim.get('stimID'):
            img = Image.open(pjoin(stim.header['path'], stim_id))
            pil_imgs.append(img)
            out_imgs.append(np.array(img))
        # prepare saliency images
        for chn_num in args.chn:
            saliency.set_layer(args.layer, chn_num)
            for img in pil_imgs:
                grad = np.abs(saliency.backprop(img))
                if args.mode == 'gray':
                    grad = np.max(grad, 0)
                grad = ip.to_pil(grad, True)
                out_imgs.append(np.array(grad))

        # -prepare row_names-
        row_names = ['chn{}'.format(chn) for chn in args.chn]
        row_names.insert(0, 'stim')

        # -prepare save path-
        if args.out is None:
            save_path = None
        else:
            save_path = pjoin(args.out, '{0}_{1}_fig{2}.jpg'.format(args.net, args.layer, count))

        n_col = len(stim)
        imgarray_show(out_imgs, n_row, n_col, row_names, args.vmin, args.vmax,
                      cmap=args.cmap, show=args.show, save_path=save_path)
        print('Finish: {0}/{1}'.format((count - 1) * batch_size + n_col, n_stim))
        count += 1


if __name__ == '__main__':
    main()
